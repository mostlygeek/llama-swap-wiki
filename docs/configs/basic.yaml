# Minimal llama-swap configuration
# This is the simplest working config with just one model

models:
  llama-8B:
    cmd: |
      llama-server
        --host 127.0.0.1 --port ${PORT}
        --model /path/to/models/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf
